import re

special_chars = [
	",",".",":","?","!","'","/","&",";","_","=","+","#","^",
    "*","~","\\","\'","\"","\u","\n","%","$","@","(",")","[","]",
    "{","}", "-", "|"
]

stop_words = [
'a',
'about',
'above',
'across',
'after',
'afterwards',
'again',
'against',
'all',
'almost',
'alone',
'along',
'already',
'also',
'although',
'always',
'am',
'among',
'amongst',
'amoungst',
'amount',
'an',
'and',
'another',
'any',
'anyhow',
'anyone',
'anything',
'anyway',
'anywhere',
'are',
'around',
'as',
'at',
'b',
'back',
'be',
'became',
'because',
'become',
'becomes',
'becoming',
'been',
'before',
'beforehand',
'behind',
'being',
'below',
'beside',
'besides',
'between',
'beyond',
'both',
'bottom',
'but',
'by',
'c',
'call',
'can',
'cannot',
'cant',
'co',
'con',
'could',
'couldnt',
'cry',
'd',
'de',
'describe',
'detail',
'do',
'done',
'down',
'due',
'during',
'e',
'each',
'eg',
'eight',
'either',
'eleven',
'else',
'elsewhere',
'empty',
'enough',
'etc',
'even',
'ever',
'every',
'everyone',
'everything',
'everywhere',
'except',
'f',
'few',
'fifteen',
'free',
'fify',
'fill',
'find',
'fire',
'first',
'five',
'for',
'former',
'formerly',
'forty',
'found',
'four',
'from',
'front',
'full',
'further',
'g',
'get',
'give',
'go',
'h',
'had',
'has',
'hasnt',
'have',
'he',
'hence',
'her',
'here',
'hereafter',
'hereby',
'herein',
'hereupon',
'hers',
'herse"',
'him',
'himse"',
'his',
'how',
'however',
'hundred',
'i',
'ie',
'if',
'in',
'inc',
'indeed',
'interest',
'into',
'is',
'it',
'its',
'itse"',
'j',
'k',
'keep',
'l',
'last',
'latter',
'latterly',
'least',
'less',
'ltd',
'm',
'made',
'many',
'may',
'me',
'meanwhile',
'might',
'mill',
'mine',
'more',
'moreover',
'most',
'mostly',
'move',
'much',
'must',
'my',
'myse"',
'n',
'name',
'namely',
'neither',
'never',
'nevertheless',
'next',
'nine',
'no',
'nobody',
'none',
'noone',
'nor',
'not',
'nothing',
'now',
'nowhere',
'o',
'of',
'off',
'often',
'on',
'once',
'one',
'only',
'onto',
'or',
'other',
'others',
'otherwise',
'our',
'ours',
'ourselves',
'out',
'over',
'own',
'p',
'part',
'per',
'perhaps',
'please',
'put',
'q',
'r',
'rather',
're',
's',
'same',
'see',
'seem',
'seemed',
'seeming',
'seems',
'serious',
'several',
'she',
'should',
'show',
'side',
'since',
'sincere',
'six',
'sixty',
'so',
'some',
'somehow',
'someone',
'something',
'sometime',
'sometimes',
'somewhere',
'still',
'such',
'system',
't',
'take',
'ten',
'than',
'that',
'the',
'their',
'them',
'themselves',
'then',
'thence',
'there',
'thereafter',
'thereby',
'therefore',
'therein',
'thereupon',
'these',
'they',
'thick',
'thin',
'third',
'this',
'those',
'though',
'three',
'through',
'throughout',
'thru',
'thus',
'to',
'together',
'too',
'top',
'toward',
'towards',
'twelve',
'twenty',
'two',
'u',
'un',
'under',
'until',
'up',
'upon',
'us',
'v',
'very',
'via',
'w',
'was',
'we',
'well',
'were',
'what',
'whatever',
'when',
'whence',
'whenever',
'where',
'whereafter',
'whereas',
'whereby',
'wherein',
'whereupon',
'wherever',
'whether',
'which',
'while',
'whither',
'who',
'whoever',
'whole',
'whom',
'whose',
'why',
'will',
'with',
'within',
'without',
'would',
'x',
'y',
'yet',
'you',
'your',
'yours',
'yourself',
'yourselves',
'z',
'NEWWORDS',
'www',
'http',
'https',
'com',
'net',
'wikipedia',
'encyclopedia',
'wiki',
'webster',
'merriam',
'dictionary',
'site',
'sites',
'org',
'en',
'us',
'html',
'htm',
'jsp',
'index',
'id',
'aspx',
'el',
'including',
'cnbc',
'espn',
'cnn'
 ]                

class WrongRangePrecisionError(Exception):
   pass

def replace_non_ascii_with_space(input_doc):
    return re.sub(r'[^\x00-\x7F]+', ' ', input_doc)

def replace_special_chars(input_doc):
    input_ascii_doc = replace_non_ascii_with_space(input_doc)
    return replace_words_with_target_str(input_ascii_doc, special_chars)

def replace_words_with_target_str(input_doc, replaced_words, target_str=" "):
    replaced_words_regex = re.compile(
        '|'.join(map(re.escape, replaced_words))
    )
    updated_text = replaced_words_regex.sub(target_str, input_doc)
    return updated_text

def count_frequency(item_str):
    item_stats = {}
    items = split_input_doc_to_words(item_str)
    for item in items:
        if item_stats.get(item):
            item_stats[item] += 1.0
        else:
            item_stats[item] = 1.0
    return item_stats

def remove_stop_words(words):
    i = 0
    while i < len(words):
        if words[i].lower() in stop_words or words[i] == '':
            words.pop(i)
        else:
            words[i] = words[i].lower()
            i += 1
    return words

def split_input_doc_to_words(input_doc):
    words = input_doc.split(' ')
    words = remove_stop_words(words)
    return words

def clean_up_title(title_str):
    ascii_title_str = replace_non_ascii_with_space(title_str)
    special_char_idx = len(ascii_title_str)
    for special_char in special_chars:
        curr_special_char_idx = ascii_title_str.find(special_char)
        if curr_special_char_idx == -1:
            continue
        else:
            if curr_special_char_idx < special_char_idx:
                special_char_idx = curr_special_char_idx        
    modified_title = title_str[:special_char_idx]
    if not modified_title:
        return title_str
    return modified_title


